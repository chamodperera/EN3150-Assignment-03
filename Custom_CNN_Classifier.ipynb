{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fe7320",
   "metadata": {},
   "source": [
    "This notebook has been imported from Kaggle. Please note that the dataset used in this notebook is not included here. However, you can find the dataset [here](https://www.kaggle.com/datasets/joebeachcapital/realwaste).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee8cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7937a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, os, subprocess, sys\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Optional, see driver details:\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for g in gpus:\n",
    "    tf.config.experimental.set_memory_growth(g, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d7f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed precision for T4 Tensor Cores\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de3916",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 64\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "DATA_DIR = \"/kaggle/input/realwaste/realwaste-main/RealWaste\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19637c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.30,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    ")\n",
    "\n",
    "temp_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    validation_split=0.30,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "class_names = train_raw.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff947ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_batches = temp_raw.cardinality().numpy()  # should be known for this dataset\n",
    "val_raw  = temp_raw.take(temp_batches // 2)\n",
    "test_raw = temp_raw.skip(temp_batches // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29c696",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73544469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(ds, num_classes):\n",
    "    counts = np.zeros(num_classes, dtype=np.int64)\n",
    "    for _, y in ds.unbatch():\n",
    "        # y may be int (sparse) or one-hot; normalize to int\n",
    "        if len(y.shape) == 0:\n",
    "            counts[int(y.numpy())] += 1\n",
    "        else:\n",
    "            counts[int(np.argmax(y.numpy()))] += 1\n",
    "    return counts\n",
    "\n",
    "train_counts = count_labels(train_raw, len(class_names))\n",
    "val_counts   = count_labels(val_raw,   len(class_names))\n",
    "test_counts  = count_labels(test_raw,  len(class_names))\n",
    "\n",
    "def bar_counts(title, counts):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.title(title)\n",
    "    plt.bar(class_names, counts)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "bar_counts(\"Train class distribution\", train_counts)\n",
    "bar_counts(\"Validation class distribution\", val_counts)\n",
    "bar_counts(\"Test class distribution\", test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "for _, y in train_raw.unbatch().take(2000):\n",
    "    ys.append(y.numpy())\n",
    "\n",
    "ys = np.array(ys)\n",
    "print(\"dtype:\", ys.dtype, \"shape:\", ys.shape)\n",
    "print(\"min/max:\", ys.min(), ys.max())\n",
    "print(\"unique:\", np.unique(ys)[:20]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1cb5f7",
   "metadata": {},
   "source": [
    "#### Augment and Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882833e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6456b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.12),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomContrast(0.2),\n",
    "], name=\"augment\")\n",
    "\n",
    "normalize = layers.Rescaling(1./255)\n",
    "\n",
    "def to_float32(x, y):  # ensure float32 before normalize\n",
    "    return tf.cast(x, tf.float32), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN: augment → normalize\n",
    "train_ds = (train_raw\n",
    "            .map(to_float32, num_parallel_calls=AUTOTUNE)\n",
    "            .map(lambda x,y: (normalize(x), y), num_parallel_calls=AUTOTUNE)\n",
    "            .map(lambda x,y: (augment(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "            .prefetch(AUTOTUNE))\n",
    "\n",
    "val_ds = (val_raw\n",
    "          .map(to_float32, num_parallel_calls=AUTOTUNE)\n",
    "          .map(lambda x,y: (normalize(x), y), num_parallel_calls=AUTOTUNE)\n",
    "          .prefetch(AUTOTUNE))\n",
    "\n",
    "test_ds = (test_raw\n",
    "           .map(to_float32, num_parallel_calls=AUTOTUNE)\n",
    "           .map(lambda x,y: (normalize(x), y), num_parallel_calls=AUTOTUNE)\n",
    "           .prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef693f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e4f94",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d69cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_act(x, filters, k, stride=1, act=\"relu\"):\n",
    "    x = layers.Conv2D(filters, k, strides=stride, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(act)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(x, filters, k, act=\"relu\"):\n",
    "    \"\"\"Two convs with a residual (skip). Uses 1x1 conv if channels mismatch.\"\"\"\n",
    "    shortcut = x\n",
    "    # First conv\n",
    "    y = conv_bn_act(x, filters, k, act=act)\n",
    "    # Second conv (no activation before add)\n",
    "    y = layers.Conv2D(filters, k, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "\n",
    "    # Match channels if needed\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, 1, padding=\"same\", use_bias=False)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    out = layers.Add()([shortcut, y])\n",
    "    out = layers.Activation(act)(out)\n",
    "    return out\n",
    "\n",
    "def build_resnet(input_shape, x1, m1, x2, m2, x3, m3, x4, x5,d, K, act=\"relu\"):\n",
    "    \"\"\"\n",
    "   - Conv layer (x1, m1) + residual block\n",
    "      - MaxPool\n",
    "      - Conv layer (x2, m2) + residual block\n",
    "      - MaxPool\n",
    "      - Flatten\n",
    "      - Dense x3 + activation\n",
    "      - Dropout d\n",
    "      - Output softmax K\n",
    "    \"\"\"\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ---- Stage 1 ----\n",
    "    x = conv_bn_act(inp, x1, m1, act=act)     # conv layer\n",
    "    x = residual_block(x, x1, m1, act=act)    # residual \n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)   # max pool\n",
    "\n",
    "    # ---- Stage 2 ----\n",
    "    x = conv_bn_act(x, x2, m2, act=act)       # conv layer\n",
    "    x = residual_block(x, x2, m2, act=act)    # residual\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)   # max pool\n",
    "\n",
    "    # ---- Stage 3 ----\n",
    "    x = conv_bn_act(x, x3, m3, act=act)       # conv layer\n",
    "    x = residual_block(x, x3, m3, act=act)    # residual\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)   # max pool\n",
    "\n",
    "    # ---- Head ----\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(x4, activation=act, kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.Dropout(d)(x)    \n",
    "\n",
    "    x = layers.Dense(x5, activation=act, kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.Dropout(d)(x)\n",
    "\n",
    "    logits = layers.Dense(K, dtype=\"float32\", name=\"logits\")(x)\n",
    "    out = layers.Activation(\"softmax\", dtype=\"float32\", name=\"softmax\")(logits)\n",
    "\n",
    "    model = keras.Model(inp, out, name=\"Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b96082",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "K = len(class_names)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_resnet(\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        x1=32, m1=3,\n",
    "        x2=64, m2=3,\n",
    "        x3=128, m3=3,\n",
    "        x4=256, x5=64, d=0.4,\n",
    "        K=K, act=\"relu\"\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=1e-3,   \n",
    "        clipnorm=1.0   \n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579b709",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Callbacks ----------------\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\", factor=0.5, patience=4, min_lr=1e-5, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", mode=\"max\", patience=10, restore_best_weights=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_rescnn.keras\", monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, verbose=1\n",
    "    ),\n",
    "    keras.callbacks.TerminateOnNaN()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81d137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Train ----------------\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys:\", list(history.history.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b618ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = history.history\n",
    "epochs = np.arange(1, len(H[\"loss\"]) + 1)\n",
    "\n",
    "# ---- Print summaries ----\n",
    "print(\"\\nFinal epoch:\")\n",
    "print(f\"  accuracy     : {H['accuracy'][-1]:.5f}\")\n",
    "print(f\"  val_accuracy : {H['val_accuracy'][-1]:.5f}\")\n",
    "print(f\"  loss         : {H['loss'][-1]:.5f}\")\n",
    "print(f\"  val_loss     : {H['val_loss'][-1]:.5f}\")\n",
    "print(f\"  learning_rate: {H['learning_rate'][-1]:.6g}\")\n",
    "\n",
    "best_va_ep = int(np.nanargmax(H[\"val_accuracy\"])) + 1\n",
    "best_vl_ep = int(np.nanargmin(H[\"val_loss\"])) + 1\n",
    "print(\"\\nBest epochs:\")\n",
    "print(f\"  best val_accuracy at epoch {best_va_ep}: {H['val_accuracy'][best_va_ep-1]:.5f}\")\n",
    "print(f\"  best val_loss     at epoch {best_vl_ep}: {H['val_loss'][best_vl_ep-1]:.5f}\")\n",
    "\n",
    "# ---- Plot: Loss ----\n",
    "plt.figure()\n",
    "plt.plot(epochs, H[\"loss\"], label=\"train loss\")\n",
    "plt.plot(epochs, H[\"val_loss\"], label=\"val loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training vs Validation Loss\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "\n",
    "# ---- Plot: Accuracy ----\n",
    "plt.figure()\n",
    "plt.plot(epochs, H[\"accuracy\"], label=\"train acc\")\n",
    "plt.plot(epochs, H[\"val_accuracy\"], label=\"val acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "\n",
    "# ---- Plot: Learning Rate ----\n",
    "plt.figure()\n",
    "plt.plot(epochs, H[\"learning_rate\"], label=\"learning rate\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"LR\"); plt.title(\"Learning Rate Schedule\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ba4b5",
   "metadata": {},
   "source": [
    "## Optimizer Comparison: Adam vs SGD vs SGD+Momentum\n",
    "We compare three optimizers on the same architecture and dataset:\n",
    "- Adam (current choice)\n",
    "- SGD (no momentum)\n",
    "- SGD with momentum (m=0.9 by default)\n",
    "\n",
    "> Metrics: validation accuracy (primary), validation loss (secondary). We prefer val accuracy to capture generalization on held‑out data, and val loss to reveal calibration/overfitting trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c568cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "# Utility to build a fresh model and compile with a given optimizer\n",
    "def make_compiled_model(optimizer):\n",
    "    model = build_resnet(\n",
    "        input_shape=INPUT_SHAPE,\n",
    "        x1=32, m1=3,\n",
    "        x2=64, m2=3,\n",
    "        x3=128, m3=3,\n",
    "        x4=256, x5=64, d=0.4,\n",
    "        K=K, act=\"relu\"\n",
    "    )\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Train helper\n",
    "def train_with_optimizer(optimizer, epochs=EPOCHS):\n",
    "    with strategy.scope():\n",
    "        m = make_compiled_model(optimizer)\n",
    "    hist = m.fit(\n",
    "        train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks, verbose=1\n",
    "    )\n",
    "    return m, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers to compare\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "sgd_opt  = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "sgdm_opt = tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=0.9)\n",
    "\n",
    "results = {}\n",
    "for name, opt in [(\"Adam\", adam_opt), (\"SGD\", sgd_opt), (\"SGD+Momentum\", sgdm_opt)]:\n",
    "    print(f\"\\n==== Training with {name} ====\")\n",
    "    m, h = train_with_optimizer(opt, epochs=EPOCHS)\n",
    "    H = h.history\n",
    "    results[name] = {\n",
    "        \"model\": m,\n",
    "        \"history\": H,\n",
    "        \"final_val_acc\": float(H.get(\"val_accuracy\", [float('nan')])[-1]),\n",
    "        \"final_val_loss\": float(H.get(\"val_loss\", [float('nan')])[-1]),\n",
    "    }\n",
    "\n",
    "print(\"\\nSummary (final epoch):\")\n",
    "for k,v in results.items():\n",
    "    print(f\"{k:>14} | val_acc: {v['final_val_acc']:.4f} | val_loss: {v['final_val_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93790a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation accuracy/loss across optimizers\n",
    "plt.figure(figsize=(10,4))\n",
    "for name, v in results.items():\n",
    "    H = v[\"history\"]\n",
    "    plt.plot(H[\"val_accuracy\"], label=f\"{name} val_acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Accuracy\"); plt.title(\"Optimizer Comparison: Validation Accuracy\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for name, v in results.items():\n",
    "    H = v[\"history\"]\n",
    "    plt.plot(H[\"val_loss\"], label=f\"{name} val_loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Loss\"); plt.title(\"Optimizer Comparison: Validation Loss\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671c7e7",
   "metadata": {},
   "source": [
    "## Momentum Impact Discussion\n",
    "We vary the momentum parameter for SGD and observe its effect on convergence and generalization.\n",
    "- Momentum helps smooth noisy gradients and accelerates optimization along consistent directions.\n",
    "- Too low (≈0.0) behaves like vanilla SGD, slower convergence.\n",
    "- Moderate (0.9) often improves stability and val accuracy.\n",
    "- Too high (>0.95–0.99) may overshoot minima and cause oscillations without careful LR tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308044aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep different momentum values\n",
    "momentums = [0.0, 0.5, 0.9]\n",
    "mom_results = {}\n",
    "for m in momentums:\n",
    "    print(f\"\\n==== Training with SGD momentum={m} ====\")\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=m)\n",
    "    model_m, hist_m = train_with_optimizer(opt, epochs=EPOCHS)\n",
    "    Hm = hist_m.history\n",
    "    mom_results[m] = {\n",
    "        \"model\": model_m,\n",
    "        \"history\": Hm,\n",
    "        \"final_val_acc\": float(Hm.get(\"val_accuracy\", [float('nan')])[-1]),\n",
    "        \"final_val_loss\": float(Hm.get(\"val_loss\", [float('nan')])[-1]),\n",
    "    }\n",
    "\n",
    "print(\"\\nMomentum sweep summary (final epoch):\")\n",
    "for m,v in mom_results.items():\n",
    "    print(f\"m={m:.2f} | val_acc: {v['final_val_acc']:.4f} | val_loss: {v['final_val_loss']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for m,v in mom_results.items():\n",
    "    plt.plot(v[\"history\"][\"val_accuracy\"], label=f\"momentum={m}\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Accuracy\"); plt.title(\"SGD Momentum Sweep: Validation Accuracy\")\n",
    "plt.grid(True); plt.legend(); plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe307cfb",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set\n",
    "We report train/validation accuracy from history and compute test accuracy, confusion matrix, precision, and recall on `test_ds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53193423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model among the optimizer comparison by val_accuracy\n",
    "best_name = max(results.keys(), key=lambda k: results[k][\"final_val_acc\"])\n",
    "best_model = results[best_name][\"model\"]\n",
    "print(f\"Best by val_accuracy: {best_name}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = best_model.evaluate(test_ds, verbose=1)\n",
    "print(\"Test metrics (loss, accuracy):\", test_metrics)\n",
    "\n",
    "# Build predictions and confusion matrix\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for x_batch, y_batch in test_ds:\n",
    "    preds = best_model.predict(x_batch, verbose=0)\n",
    "    y_true.extend(y_batch.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
